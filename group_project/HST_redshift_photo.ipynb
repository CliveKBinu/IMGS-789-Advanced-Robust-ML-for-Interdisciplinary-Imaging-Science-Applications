{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ckb2084/research/IMGS-789-Advanced-Robust-ML-for-Interdisciplinary-Imaging-Science-Applications/group_project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckb2084/conda/envs/pytorch/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd IMGS-789-Advanced-Robust-ML-for-Interdisciplinary-Imaging-Science-Applications/group_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1705367/2093688170.py:17: DeprecationWarning: Please import `gaussian_filter1d` from the `scipy.ndimage` namespace; the `scipy.ndimage.filters` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.filters import gaussian_filter1d\n"
     ]
    }
   ],
   "source": [
    "# Neccesary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from time import time\n",
    "import random\n",
    "import glob, os\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from accelerate import Accelerator\n",
    "cm = plt.get_cmap('RdYlBu')\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import LayerNorm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import gaussian_kde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 2.47 s, total: 3.8 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Import all the data\n",
    "\n",
    "data = pd.read_pickle('grism_specPT.pkl')\n",
    "data_sed = pd.read_pickle('sed_fitting.pkl')\n",
    "# data_photo = pd.read_pickle('photo_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(232.9991061854824)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sed['best.chi_square'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1       12.121545\n",
       "2       12.427232\n",
       "3       15.264308\n",
       "4       12.558336\n",
       "          ...    \n",
       "5968     2.206474\n",
       "5969     1.183323\n",
       "5970     0.965716\n",
       "5971     1.914446\n",
       "5972     0.305017\n",
       "Name: best.chi_square, Length: 5973, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(data_sed['best.chi_square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bayes.sfh.sfr</th>\n",
       "      <th>bayes.sfh.sfr_err</th>\n",
       "      <th>bayes.sfh.sfr100Myrs</th>\n",
       "      <th>bayes.sfh.sfr100Myrs_err</th>\n",
       "      <th>bayes.sfh.sfr10Myrs</th>\n",
       "      <th>bayes.sfh.sfr10Myrs_err</th>\n",
       "      <th>bayes.CTIO_MosaicII.U</th>\n",
       "      <th>bayes.CTIO_MosaicII.U_err</th>\n",
       "      <th>bayes.KPNOU</th>\n",
       "      <th>...</th>\n",
       "      <th>best.subaru.suprime.NB816</th>\n",
       "      <th>best.subaru.suprime.IB827</th>\n",
       "      <th>best.cfht.wircam.J</th>\n",
       "      <th>best.cfht.wircam.H</th>\n",
       "      <th>best.cfht.wircam.Ks</th>\n",
       "      <th>best.KPNOU</th>\n",
       "      <th>best.CTIO_MosaicII.U</th>\n",
       "      <th>best.ukirt.J</th>\n",
       "      <th>best.ukirt.H</th>\n",
       "      <th>best.ukirt.Ks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>103.423556</td>\n",
       "      <td>57.306127</td>\n",
       "      <td>62.311362</td>\n",
       "      <td>34.981520</td>\n",
       "      <td>105.150274</td>\n",
       "      <td>58.259412</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.013055</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.012906</td>\n",
       "      <td>0.016440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14.831638</td>\n",
       "      <td>7.785192</td>\n",
       "      <td>8.749829</td>\n",
       "      <td>4.625168</td>\n",
       "      <td>15.013204</td>\n",
       "      <td>7.901320</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16.269784</td>\n",
       "      <td>9.253563</td>\n",
       "      <td>9.512016</td>\n",
       "      <td>5.192185</td>\n",
       "      <td>16.512681</td>\n",
       "      <td>9.419896</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>3.0</td>\n",
       "      <td>21.366991</td>\n",
       "      <td>11.922256</td>\n",
       "      <td>12.880794</td>\n",
       "      <td>7.282398</td>\n",
       "      <td>21.725772</td>\n",
       "      <td>12.118329</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.004051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>4.0</td>\n",
       "      <td>41.873706</td>\n",
       "      <td>24.168218</td>\n",
       "      <td>26.424520</td>\n",
       "      <td>15.494340</td>\n",
       "      <td>42.652539</td>\n",
       "      <td>24.549463</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.006112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5968</th>\n",
       "      <td>6047.0</td>\n",
       "      <td>76.736727</td>\n",
       "      <td>23.670309</td>\n",
       "      <td>63.522755</td>\n",
       "      <td>20.811619</td>\n",
       "      <td>77.810823</td>\n",
       "      <td>23.763980</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5969</th>\n",
       "      <td>6054.0</td>\n",
       "      <td>12.970196</td>\n",
       "      <td>5.848309</td>\n",
       "      <td>8.519633</td>\n",
       "      <td>3.633422</td>\n",
       "      <td>13.112897</td>\n",
       "      <td>5.918852</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>6042.0</td>\n",
       "      <td>12.168651</td>\n",
       "      <td>5.186683</td>\n",
       "      <td>7.867744</td>\n",
       "      <td>2.853938</td>\n",
       "      <td>12.310875</td>\n",
       "      <td>5.268632</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.001861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>6051.0</td>\n",
       "      <td>39.028449</td>\n",
       "      <td>16.517668</td>\n",
       "      <td>27.610050</td>\n",
       "      <td>9.801470</td>\n",
       "      <td>39.358946</td>\n",
       "      <td>16.682189</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>6043.0</td>\n",
       "      <td>26.915372</td>\n",
       "      <td>13.146285</td>\n",
       "      <td>18.676981</td>\n",
       "      <td>7.597407</td>\n",
       "      <td>27.220008</td>\n",
       "      <td>13.313217</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.002643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  bayes.sfh.sfr  bayes.sfh.sfr_err  bayes.sfh.sfr100Myrs  \\\n",
       "1031     0.0     103.423556          57.306127             62.311362   \n",
       "1032     1.0      14.831638           7.785192              8.749829   \n",
       "1033     2.0      16.269784           9.253563              9.512016   \n",
       "1034     3.0      21.366991          11.922256             12.880794   \n",
       "1035     4.0      41.873706          24.168218             26.424520   \n",
       "...      ...            ...                ...                   ...   \n",
       "5968  6047.0      76.736727          23.670309             63.522755   \n",
       "5969  6054.0      12.970196           5.848309              8.519633   \n",
       "5970  6042.0      12.168651           5.186683              7.867744   \n",
       "5971  6051.0      39.028449          16.517668             27.610050   \n",
       "5972  6043.0      26.915372          13.146285             18.676981   \n",
       "\n",
       "      bayes.sfh.sfr100Myrs_err  bayes.sfh.sfr10Myrs  bayes.sfh.sfr10Myrs_err  \\\n",
       "1031                 34.981520           105.150274                58.259412   \n",
       "1032                  4.625168            15.013204                 7.901320   \n",
       "1033                  5.192185            16.512681                 9.419896   \n",
       "1034                  7.282398            21.725772                12.118329   \n",
       "1035                 15.494340            42.652539                24.549463   \n",
       "...                        ...                  ...                      ...   \n",
       "5968                 20.811619            77.810823                23.763980   \n",
       "5969                  3.633422            13.112897                 5.918852   \n",
       "5970                  2.853938            12.310875                 5.268632   \n",
       "5971                  9.801470            39.358946                16.682189   \n",
       "5972                  7.597407            27.220008                13.313217   \n",
       "\n",
       "      bayes.CTIO_MosaicII.U  bayes.CTIO_MosaicII.U_err  bayes.KPNOU  ...  \\\n",
       "1031               0.002728                   0.002030     0.002731  ...   \n",
       "1032               0.000660                   0.000300     0.000677  ...   \n",
       "1033               0.000584                   0.000329     0.000584  ...   \n",
       "1034               0.000480                   0.000366     0.000481  ...   \n",
       "1035               0.000604                   0.000402     0.000612  ...   \n",
       "...                     ...                        ...          ...  ...   \n",
       "5968               0.000107                   0.000014     0.000118  ...   \n",
       "5969               0.000434                   0.000051     0.000436  ...   \n",
       "5970               0.000751                   0.000086     0.000747  ...   \n",
       "5971               0.000389                   0.000042     0.000402  ...   \n",
       "5972               0.000635                   0.000085     0.000648  ...   \n",
       "\n",
       "      best.subaru.suprime.NB816  best.subaru.suprime.IB827  \\\n",
       "1031                   0.003328                   0.003380   \n",
       "1032                   0.000967                   0.000922   \n",
       "1033                   0.000722                   0.000725   \n",
       "1034                   0.000661                   0.000667   \n",
       "1035                   0.000908                   0.000906   \n",
       "...                         ...                        ...   \n",
       "5968                   0.000560                   0.000570   \n",
       "5969                   0.000583                   0.000587   \n",
       "5970                   0.000947                   0.000947   \n",
       "5971                   0.000900                   0.000906   \n",
       "5972                   0.001024                   0.001028   \n",
       "\n",
       "      best.cfht.wircam.J  best.cfht.wircam.H  best.cfht.wircam.Ks  best.KPNOU  \\\n",
       "1031            0.009851            0.013055             0.016491    0.002237   \n",
       "1032            0.000894            0.000781             0.000816    0.001226   \n",
       "1033            0.001758            0.001558             0.001096    0.000838   \n",
       "1034            0.001557            0.002254             0.004027    0.000288   \n",
       "1035            0.002741            0.004240             0.006092    0.000642   \n",
       "...                  ...                 ...                  ...         ...   \n",
       "5968            0.001303            0.002737             0.004181    0.000125   \n",
       "5969            0.001417            0.001508             0.001391    0.000417   \n",
       "5970            0.002031            0.001735             0.001845    0.000732   \n",
       "5971            0.002120            0.002453             0.002868    0.000393   \n",
       "5972            0.002102            0.002375             0.002640    0.000642   \n",
       "\n",
       "      best.CTIO_MosaicII.U  best.ukirt.J  best.ukirt.H  best.ukirt.Ks  \n",
       "1031              0.002206      0.009927      0.012906       0.016440  \n",
       "1032              0.001199      0.000897      0.000789       0.000816  \n",
       "1033              0.000837      0.001728      0.001534       0.001127  \n",
       "1034              0.000287      0.001539      0.002255       0.004051  \n",
       "1035              0.000644      0.002726      0.004247       0.006112  \n",
       "...                    ...           ...           ...            ...  \n",
       "5968              0.000113      0.001277      0.002745       0.004187  \n",
       "5969              0.000410      0.001392      0.001505       0.001393  \n",
       "5970              0.000736      0.002033      0.001732       0.001861  \n",
       "5971              0.000380      0.002050      0.002466       0.002872  \n",
       "5972              0.000627      0.002070      0.002385       0.002643  \n",
       "\n",
       "[4360 rows x 207 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sed_chi_l5 = data_sed[data_sed['best.redchi_square'] <= 5.0]\n",
    "data_sed_chi_l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 14, 19, 20, 18, 21, 22, 23, 26, 24, 27, 28, 29, 31, 32, 30, 35, 34, 33, 36, 37, 39, 38, 41, 43, 44, 46, 48, 50, 51, 52, 56, 54, 58, 57, 63, 66, 62, 65, 67, 68, 80, 71, 69, 73, 70, 86, 72, 76, 75, 77, 78, 79, 74, 82, 81, 84, 87, 88, 89, 90, 92, 91, 94, 95, 96, 97, 98, 99, 110, 101, 102, 104, 103, 105, 106, 107, 108, 109, 112, 111, 113, 115, 114, 116, 118, 117, 119, 120, 123, 122, 126, 128, 129, 132, 130, 131, 134, 133, 135, 136, 137, 140, 138, 139, 141, 142, 143, 144, 145, 147, 146, 150, 151, 152, 153, 156, 155, 154, 157, 159, 162, 161, 160, 163, 164, 167, 166, 168, 170, 171, 173, 172, 169, 175, 177, 176, 178, 174, 179, 183, 185, 184, 186, 187, 189, 193, 192, 194, 195, 196, 197, 200, 198, 199, 201, 202, 203, 205, 204, 207, 210, 212, 213, 211, 215, 217, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 206, 233, 229, 232, 231, 230, 234, 236, 228, 237, 239, 240, 238, 214, 242, 243, 244, 241, 246, 245, 248, 247, 249, 250, 251, 252, 253, 255, 256, 254, 258, 259, 261, 260, 262, 268, 266, 267, 263, 269, 265, 270, 276, 275, 273, 277, 274, 279, 278, 286, 283, 280, 281, 284, 282, 285, 287, 289, 288, 292, 290, 293, 295, 294, 296, 300, 301, 297, 302, 299, 304, 303, 298, 305, 306, 307, 308, 310, 313, 311, 314, 320, 315, 318, 317, 316, 322, 319, 324, 321, 325, 327, 328, 326, 329, 331, 330, 332, 333, 336, 334, 340, 337, 339, 338, 345, 348, 343, 350, 346, 347, 351, 349, 352, 353, 354, 356, 355, 357, 358, 360, 359, 362, 363, 361, 368, 344, 364, 365, 369, 367, 366, 373, 370, 372, 371, 374, 380, 375, 376, 377, 381, 379, 383, 382, 384, 388, 385, 387, 390, 389, 391, 392, 393, 396, 397, 398, 395, 401, 399, 400, 403, 402, 404, 405, 406, 407, 409, 410, 411, 413, 408, 412, 414, 416, 415, 417, 419, 420, 422, 421, 423, 426, 424, 428, 432, 427, 430, 429, 433, 435, 437, 439, 438, 434, 441, 440, 443, 444, 442, 445, 461, 446, 447, 450, 449, 448, 454, 453, 457, 456, 455, 458, 460, 463, 489, 462, 466, 465, 469, 471, 470, 474, 467, 478, 475, 480, 479, 481, 473, 482, 486, 488, 485, 487, 491, 490, 494, 496, 499, 497, 498, 501, 504, 502, 505, 506, 508, 495, 507, 509, 510, 511, 512, 516, 520, 517, 519, 522, 523, 518, 524, 521, 515, 525, 527, 526, 528, 530, 532, 531, 533, 535, 529, 537, 536, 534, 539, 540, 538, 542, 541, 544, 543, 546, 547, 550, 548, 552, 581, 555, 553, 554, 557, 551, 556, 558, 559, 560, 561, 562, 563, 566, 567, 569, 568, 570, 572, 564, 573, 575, 574, 579, 580, 582, 578, 577, 585, 586, 587, 588, 583, 589, 590, 593, 592, 591, 594, 595, 610, 597, 598, 596, 601, 599, 600, 603, 602, 606, 607, 605, 608, 604, 609, 612, 611, 614, 613, 615, 616, 617, 618, 620, 622, 626, 625, 621, 624, 627, 629, 630, 628, 634, 633, 638, 636, 632, 639, 640, 642, 643, 641, 644, 645, 647, 646, 652, 649, 651, 656, 654, 655, 653, 658, 657, 659, 660, 661, 662, 664, 665, 663, 667, 666, 668, 669, 670, 671, 672, 673, 674, 675, 677, 676, 678, 679, 680, 681, 682, 684, 686, 683, 685, 689, 688, 692, 687, 690, 691, 694, 693, 695, 698, 700, 697, 699, 701, 703, 702, 705, 704, 707, 708, 710, 709, 711, 712, 713, 714, 716, 715, 717, 718, 719, 722, 721, 720, 725, 724, 730, 726, 727, 728, 732, 735, 733, 736, 731, 737, 734, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 752, 749, 750, 751, 754, 753, 756, 755, 757, 758, 761, 763, 759, 762, 766, 765, 760, 767, 768, 773, 772, 769, 774, 770, 771, 780, 776, 781, 779, 775, 777, 778, 782, 783, 791, 786, 784, 787, 793, 792, 790, 789, 796, 795, 788, 794, 797, 798, 800, 799, 802, 801, 806, 804, 807, 805, 809, 810, 812, 811, 814, 813, 816, 819, 815, 818, 817, 825, 821, 822, 820, 823, 824, 826, 827, 828, 829, 831, 830, 832, 833, 835, 834, 839, 837, 836, 843, 838, 840, 842, 845, 844, 847, 846, 841, 848, 850, 849, 852, 851, 858, 853, 854, 856, 857, 855, 859, 860, 863, 862, 864, 866, 867, 868, 865, 869, 870, 871, 874, 872, 876, 875, 878, 877, 881, 892, 884, 882, 883, 880, 886, 885, 889, 893, 888, 894, 890, 895, 898, 891, 897, 900, 896, 903, 902, 899, 906, 904, 907, 909, 908, 911, 910, 901, 913, 915, 916, 917, 918, 922, 925, 920, 924, 919, 923, 926, 928, 927, 929, 930, 932, 933, 931, 935, 937, 942, 936, 934, 939, 940, 938, 941, 943, 944, 945, 946, 947, 948, 953, 950, 952, 957, 954, 955, 959, 956, 958, 962, 961, 965, 963, 966, 964, 970, 967, 969, 973, 971, 972, 968, 974, 977, 975, 980, 976, 978, 979, 982, 985, 983, 981, 984, 987, 988, 986, 989, 991, 992, 997, 999, 990, 993, 994, 996, 998, 995, 1000, 1003, 1002, 1001, 1004, 1005, 1006, 1007, 1008, 1010, 1009, 1012, 1011, 1013, 1014, 1015, 1016, 1018, 1017, 1020, 1021, 1019, 1023, 1022, 1024, 1025, 1026, 1027, 1028, 1030, 1029, 1033, 1034, 1032, 1035, 1037, 1036, 1039, 1038, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1051, 1055, 1052, 1053, 1054, 1057, 1049, 1056, 1058, 1060, 1059, 1061, 1071, 1062, 1067, 1064, 1068, 1069, 1072, 1075, 1073, 1076, 1074, 1077, 1078, 1080, 1082, 1081, 1084, 1088, 1087, 1086, 1079, 1089, 1090, 1097, 1095, 1093, 1091, 1092, 1096, 1094, 1099, 1103, 1104, 1101, 1100, 1098, 1107, 1106, 1108, 1109, 1111, 1112, 1110, 1113, 1115, 1114, 1116, 1117, 1118, 1119, 1120, 1122, 1123, 1124, 1132, 1125, 1127, 1128, 1197, 1131, 1133, 1134, 1161, 1129, 1237, 1137, 1248, 1234, 1251, 1136, 1226, 1236, 1239, 1243, 1240, 1221, 1231, 1233, 1238, 1230, 1217, 1227, 1149, 1220, 1223, 1247, 1198, 1211, 1208, 1214, 1228, 1213, 1210, 1209, 1207, 1219, 1215, 1204, 1218, 1199, 1200, 1201, 1202, 1216, 1189, 1224, 1190, 1196, 1205, 1193, 1225, 1191, 1182, 1222, 1181, 1142, 1179, 1180, 1159, 1169, 1173, 1172, 1160, 1186, 1183, 1168, 1188, 1174, 1171, 1192, 1166, 1185, 1157, 1187, 1212, 1150, 1164, 1130, 1146, 1156, 1152, 1148, 1163, 1145, 1141, 1176, 1143, 1158, 1153, 1144, 1177, 1140, 1151, 1135, 1162, 1175, 1154, 1203, 1147, 1139, 2292, 2294, 2296, 2299, 2298, 2302, 2305, 2307, 2306, 2309, 2310, 2311, 2308, 2312, 2315, 2313, 2317, 2318, 2319, 2314, 2321, 2324, 2322, 2320, 2323, 2325, 2326, 2331, 2330, 2327, 2329, 2328, 2332, 2333, 2334, 2335, 2338, 2341, 2337, 2342, 2340, 2350, 2348, 2346, 2347, 2351, 2349, 2343, 2345, 2344, 2353, 2352, 2354, 2355, 2358, 2357, 2359, 2356, 2365, 2366, 2364, 2360, 2363, 2367, 2369, 2368, 2362, 2371, 2376, 2374, 2378, 2377, 2375, 2372, 2373, 2387, 2383, 2361, 2382, 2393, 2380, 2389, 2381, 2386, 2390, 2388, 2400, 2398, 2395, 2408, 2405, 2379, 2410, 2411, 2385, 2409, 2407, 2402, 2401, 2413, 2415, 2406, 2414, 2394, 2412, 2421, 2416, 2422, 2419, 2403, 2424, 2423, 2426, 2420, 2429, 2430, 2427, 2431, 2425, 2428, 2434, 2435, 2436, 2437, 2442, 2444, 2441, 2432, 2443, 2445, 2449, 2450, 2448, 2447, 2452, 2451, 2456, 2453, 2454, 2455, 2459, 2446, 2458, 2460, 2433, 2461, 2462, 2464, 2465, 2467, 2466, 2470, 2469, 2474, 2468, 2473, 2457, 2476, 2475, 2482, 2471, 2477, 2480, 2484, 2486, 2489, 2487, 2493, 2485, 2478, 2479, 2481, 2494, 2488, 2490, 2496, 2497, 2491, 2499, 2501, 2506, 2503, 2508, 2498, 2512, 2515, 2500, 2504, 2511, 2509, 2519, 2516, 2517, 2507, 2521, 2522, 2492, 2520, 2525, 2514, 2523, 2524, 2526, 2530, 2529, 2510, 2513, 2532, 2533, 2518, 2538, 2541, 2544, 2528, 2540, 2527, 2542, 2535, 2549, 2539, 2551, 2531, 2545, 2536, 2552, 2558, 2543, 2555, 2554, 2560, 2561, 2534, 2547, 2546, 2563, 2559, 2565, 2564, 2557, 2571, 2569, 2573, 2574, 2570, 2572, 2578, 2583, 2582, 2575, 2581, 2585, 2591, 2576, 2579, 2587, 2590, 2577, 2592, 2586, 2584, 2599, 2600, 2596, 2580, 2597, 2594, 2601, 2605, 2606, 2608, 2595, 2615, 2612, 2603, 2609, 2616, 2598, 2613, 2604, 2610, 2620, 2626, 2589, 2627, 2629, 2632, 2631, 2625, 2633, 2602, 2621, 2622, 2635, 2634, 2617, 2619, 2614, 2641, 2638, 2646, 2647, 2623, 2639, 2643, 2649, 2648, 2618, 2645, 2654, 2640, 2653, 2657, 2644, 2659, 2658, 2660, 2661, 2656, 2665, 2662, 2663, 2668, 2664, 2670, 2671, 2672, 2652, 2674, 2655, 2667, 2676, 2673, 2677, 2678, 2669, 2675, 2679, 2651, 2683, 2681, 2680, 2684, 2682, 2685, 2687, 2636, 2688, 2686, 2689, 2692, 2693, 2691, 2701, 2703, 2706, 2697, 2694, 2707, 2709, 2696, 2704, 2708, 2713, 2712, 2711, 2715, 2718, 2719, 2710, 2716, 2702, 2690, 2721, 2720, 2723, 2722, 2724, 2726, 2727, 2729, 2731, 2714, 2730, 2728, 2732, 2698, 2733, 2735, 2739, 2740, 2741, 2742, 2743, 2744, 2725, 2746, 2748, 2749, 2750, 2737, 2751, 2752, 2753, 2755, 2736, 2754, 2757, 2758, 2756, 2766, 2745, 2759, 2764, 2762, 2760, 2767, 2768, 2769, 2770, 2734, 2763, 2772, 2771, 2777, 2778, 2774, 2776, 2779, 2782, 2784, 2785, 2775, 2783, 2780, 2773, 2789, 2781, 2788, 2790, 2791, 2786, 2794, 2795, 2799, 2801, 2798, 2765, 2761, 2803, 2804, 2793, 2802, 2806, 2805, 2792, 2810, 2812, 2811, 2808, 2813, 2815, 2796, 2816, 2817, 2818, 2807, 2819, 2797, 2820, 2822, 2814, 2823, 2824, 2825, 2828, 2829, 2821, 2831, 2833, 2826, 2834, 2836, 2838, 2839, 2844, 2848, 2849, 2850, 2855, 2854, 2858, 2842, 2859, 2843, 2861, 2847, 2863, 2862, 2864, 2866, 2868, 2853, 2870, 2867, 2827, 2869, 2872, 2856, 2873, 2875, 2871, 2878, 2877, 2880, 2883, 2886, 2879, 2885, 2835, 2884, 2888, 2890, 2891, 2892, 2895, 2893, 2897, 2881, 2904, 2906, 2900, 2905, 2909, 2908, 2907, 2911, 2910, 2912, 2841, 2898, 2917, 2915, 2901, 2902, 2921, 2926, 2925, 2922, 2927, 2932, 2929, 2933, 2931, 2918, 2936, 2934, 2903, 2930, 2938, 2939, 2889, 2887, 2943, 2941, 2928, 2950, 2942, 2935, 2944, 2940, 2954, 2958, 2945, 2957, 2920, 2960, 2953, 2961, 2951, 2965, 2952, 2959, 2968, 2949, 2966, 2971, 2948, 2972, 2967, 2973, 2976, 2956, 2977, 2979, 2975, 2974, 2970, 2980, 2962, 2981, 2982, 2947, 2983, 2984, 2989, 2987, 2990, 2985, 2992, 2993, 2994, 2991, 2997, 3002, 2996, 2999, 2986, 3001, 3003, 2998, 3006, 3004, 3005, 3000, 3008, 3009, 3007, 3013, 3014, 2995, 3015, 3010, 3017, 3018, 3020, 3016, 3011, 3023, 3027, 3024, 3019, 3030, 3029, 3035, 3022, 3036, 3034, 3037, 3032, 3039, 3025, 3038, 3040, 3028, 3042, 3041, 3043, 3046, 3044, 3047, 3049, 3050, 3048, 3052, 3056, 3057, 3059, 3063, 3061, 3062, 3058, 3060, 3065, 3053, 3054, 3045, 3069, 3071, 3074, 3079, 3077, 3078, 3081, 3072, 3080, 3068, 3070, 3083, 3082, 3086, 3075, 3087, 3085, 3088, 3091, 3090, 3098, 3093, 3096, 3102, 3103, 3100, 3094, 3104, 3067, 3092, 3064, 3099, 3106, 3108, 3109, 3105, 3111, 3110, 3115, 3114, 3112, 3116, 3122, 3101, 3118, 3123, 3125, 3107, 3076, 3131, 3124, 3132, 3134, 3130, 3136, 3140, 3141, 3142, 3117, 3128, 3119, 3133, 3144, 3126, 3120, 3148, 3143, 3151, 3137, 3152, 3097, 3154, 3155, 3156, 3127, 3145, 3150, 3159, 3158, 3161, 3160, 3129, 3149, 3168, 3169, 3166, 3171, 3164, 3172, 3167, 3177, 3176, 3180, 3178, 3181, 3179, 3183, 3184, 3185, 3113, 3182, 3186, 3187, 3162, 3170, 3188, 3153, 3174, 3190, 3191, 3194, 3195, 3192, 3197, 3198, 3199, 3201, 3196, 3203, 3205, 3193, 3207, 3208, 3209, 3211, 3212, 3213, 3210, 3214, 3200, 3216, 3217, 3218, 3220, 3219, 3221, 3225, 3226, 3228, 3229, 3227, 3215, 3232, 3233, 3231, 3230, 3235, 3234, 3238, 3237, 3240, 3241, 3236, 3242, 3245, 3244, 3239, 3243, 3246, 3249, 3247, 3252, 3223, 3248, 3253, 3254, 3256, 3258, 3257, 3261, 3259, 3260, 3262, 3263, 3267, 3266, 3268, 3270, 3269, 3265, 3271, 3273, 3274, 3277, 3276, 3250, 3255, 3272, 3280, 3281, 3282, 3286, 3279, 3287, 3285, 3290, 3294, 3293, 3288, 3284, 3289, 3283, 3291, 3295, 3296, 3299, 3300, 3298, 3275, 3302, 3303, 3301, 3305, 3308, 3309, 3314, 3311, 3310, 3317, 3316, 3318, 3321, 3322, 3320, 3315, 3313, 3306, 3304, 3325, 3329, 3330, 3328, 3331, 3333, 3326, 3332, 3337, 3339, 3319, 3327, 3324, 3336, 3338, 3343, 3341, 3323, 3345, 3335, 3346, 3348, 3349, 3347, 3353, 3352, 3350, 3355, 3359, 3356, 3344, 3358, 3360, 3351, 3357, 3363, 3366, 3334, 3371, 3362, 3361, 3354, 3364, 3373, 3365, 3369, 3375, 3374, 3370, 3372, 3376, 3378, 3377, 3367, 3379, 3382, 3383, 3381, 3384, 3390, 3388, 3392, 3387, 3391, 3386, 3393, 3380, 3389, 3396, 3394, 3385, 3399, 3395, 3398, 3401, 3397, 3402, 3403, 3408, 3404, 3407, 3406, 3411, 3410, 3415, 3414, 3416, 3405, 3413, 3418, 3419, 3417, 3424, 3423, 3420, 3425, 3422, 3412, 3426, 3430, 3429, 3432, 3433, 3431, 3440, 3437, 3434, 3441, 3438, 3439, 3421, 3436, 3445, 3435, 3444, 3442, 3447, 3449, 3446, 3443, 3448, 3459, 3472, 3457, 3466, 3461, 3516, 3460, 3453, 3455, 3450, 3452, 3451, 3635, 3649, 3647, 3654, 3646, 3644, 3637, 3655, 3634, 3627, 3639, 3623, 3636, 3454, 3626, 3641, 3633, 3621, 3629, 3648, 3617, 3631, 3618, 3615, 3619, 3628, 3622, 3607, 3611, 3625, 3599, 3624, 3620, 3593, 3606, 3613, 3610, 3589, 3614, 3638, 3603, 3608, 3609, 3600, 3604, 3590, 3643, 3632, 3602, 3583, 3616, 3642, 3584, 3597, 3586, 3598, 3588, 3580, 3591, 3581, 3577, 3579, 3571, 3573, 3576, 3572, 3557, 3575, 3569, 3560, 3563, 3565, 3564, 3562, 3570, 3553, 3549, 3555, 3582, 3561, 3551, 3554, 3596, 3558, 3567, 3556, 3566, 3545, 3544, 3559, 3595, 3548, 3536, 3535, 3534, 3540, 3532, 3528, 3539, 3533, 3530, 3538, 3517, 3520, 3523, 3527, 3525, 3519, 3521, 3526, 3537, 3510, 3507, 3514, 3513, 3496, 3504, 3524, 3501, 3509, 3503, 3543, 3495, 3511, 3499, 3492, 3502, 3493, 3482, 3531, 3505, 3518, 3491, 3500, 3485, 3494, 3498, 3488, 3465, 3483, 3490, 3489, 3497, 3478, 3487, 3475, 3477, 3486, 3484, 3479, 3481, 3473, 3480, 3469, 3458, 3467, 3468, 3471, 3470, 3474, 3464, 3462, 3463, 3659, 3660, 3662, 3663, 3661, 3665, 3668, 3666, 3667, 3669, 3670, 3671, 3672, 3676, 3673, 3675, 3677, 3682, 3679, 3680, 3674, 3686, 3687, 3678, 3683, 3689, 3688, 3690, 3694, 3692, 3693, 3695, 3691, 3697, 3700, 3698, 3699, 3702, 3704, 3706, 3703, 3701, 3708, 3709, 3705, 3710, 3712, 3707, 3715, 3718, 3716, 3713, 3720, 3711, 3717, 3719, 3721, 3722, 3724, 3726, 3728, 3725, 3730, 3731, 3733, 3723, 3734, 3735, 3738, 3737, 3742, 3736, 3739, 3741, 3732, 3743, 3740, 3749, 3754, 3753, 3745, 3752, 3748, 3750, 3747, 3755, 3757, 3762, 3756, 3760, 3758, 3761, 3744, 3727, 3751, 3763, 3764, 3766, 3769, 3767, 3768, 3770, 3771, 3765, 3759, 3772, 3773, 3774, 3775, 3779, 3780, 3777, 3776, 3778, 3782, 3781, 3783, 3786, 3785, 3788, 3790, 3792, 3787, 3796, 3797, 3801, 3803, 3804, 3800, 3802, 3789, 3805, 3809, 3791, 3793, 3807, 3799, 3811, 3808, 3810, 3806, 3815, 3812, 3817, 3816, 3813, 3827, 3829, 3828, 3820, 3823, 3822, 3814, 3825, 3832, 3818, 3831, 3824, 3834, 3833, 3830, 3837, 3819, 3839, 3821, 3836, 3826, 3840, 3838, 3835, 3841, 3843, 3846, 3848, 3844, 3849, 3852, 3845, 3853, 3850, 3854, 3851, 3857, 3856, 3859, 3858, 3860, 3862, 3861, 3863, 3842, 3847, 3866, 3867, 3868, 3869, 3872, 3870, 3873, 3871, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3883, 3885, 3888, 3887, 3886, 3889, 3891, 3892, 3895, 3890, 3894, 3897, 3884, 3900, 3901, 3902, 3899, 3906, 3905, 3904, 3908, 3882, 3909, 3911, 3913, 3915, 3907, 3914, 3916, 3917, 3922, 3921, 3924, 3920, 3926, 3927, 3930, 3928, 3931, 3933, 3934, 3937, 3938, 3939, 3936, 3942, 3941, 3947, 3932, 3946, 3944, 3943, 3945, 3948, 3949, 3950, 3951, 3955, 3954, 3953, 3956, 3962, 3958, 3963, 3959, 3961, 3966, 3965, 3968, 3969, 3967, 3972, 3975, 3971, 3970, 3974, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3988, 3987, 3989, 3985, 3991, 3993, 3994, 3997, 3996, 4000, 4002, 4004, 4003, 4009, 4010, 4013, 4011, 4008, 4016, 4018, 4020, 4022, 4019, 4026, 4027, 4028, 4030, 4029, 4034, 4032, 4035, 4024, 4033, 4012, 4038, 4040, 4041, 4042, 4043, 4044, 4045, 4039, 4046, 4048, 4049, 4047, 4036, 4050, 4051, 4052, 4053, 4055, 4058, 4057, 4064, 4066, 4061, 4059, 4056, 4070, 4062, 4069, 4072, 4063, 4068, 4067, 4074, 4076, 4073, 4075, 4077, 4079, 4078, 4071, 4085, 4080, 4089, 4082, 4086, 4087, 4096, 4091, 4088, 4097, 4098, 4094, 4065, 4099, 4100, 4093, 4104, 4102, 4101, 4092, 4095, 4108, 4110, 4106, 4109, 4114, 4115, 4113, 4107, 4112, 4118, 4111, 4120, 4119, 4117, 4128, 4124, 4122, 4125, 4129, 4126, 4105, 4134, 4130, 4131, 4133, 4132, 4141, 4139, 4135, 4142, 4136, 4138, 4144, 4146, 4145, 4143, 4147, 4148, 4149, 4151, 4150, 4155, 4153, 4156, 4157, 4170, 4165, 4161, 4172, 4162, 4177, 4174, 4159, 4176, 4167, 4175, 4164, 4158, 4180, 4178, 4140, 4182, 4173, 4168, 4179, 4183, 4169, 4163, 4186, 4185, 4184, 4154, 4181, 4187, 4188, 4190, 4191, 4189, 4193, 4160, 4198, 4196, 4192, 4197, 4195, 4194, 4199, 4201, 4202, 4200, 4204, 4206, 4203, 4210, 4208, 4209, 4211, 4212, 4207, 4214, 4213, 4215, 4205, 4217, 4216, 4219, 4218, 4221, 4220, 4223, 4224, 4222, 4225, 4227, 4226, 4228, 4229, 4230, 4231, 4234, 4233, 4235, 4236, 4232, 4238, 4239, 4240, 4241, 4242, 4243, 4249, 4244, 4245, 4247, 4246, 4248, 4252, 4259, 4251, 4254, 4255, 4262, 4256, 4260, 4257, 4261, 4263, 4265, 4268, 4258, 4267, 4266, 4270, 4269, 4273, 4272, 4277, 4253, 4276, 4278, 4274, 4279, 4280, 4281, 4283, 4285, 4286, 4287, 4282, 4288, 4289, 4293, 4295, 4291, 4296, 4294, 4292, 4298, 4299, 4301, 4302, 4290, 4303, 4304, 4305, 4275, 4307, 4309, 4306, 4311, 4310, 4313, 4314, 4318, 4315, 4316, 4317, 4319, 4321, 4323, 4322, 4326, 4325, 4329, 4297, 4327, 4308, 4331, 4330, 4332, 4333, 4336, 4334, 4337, 4347, 4335, 4338, 4344, 4339, 4320, 4341, 4352, 4343, 4342, 4346, 4340, 4349, 4345, 4348, 4284, 4350, 4351, 4353, 4356, 4354, 4358, 4360, 4359, 4361, 4355, 4363, 4364, 4365, 4366, 4367, 4370, 4372, 4374, 4371, 4368, 4378, 4379, 4373, 4376, 4377, 4381, 4380, 4385, 4375, 4387, 4394, 4383, 4393, 4391, 4390, 4382, 4395, 4397, 4398, 4401, 4404, 4405, 4406, 4410, 4386, 4408, 4412, 4392, 4396, 4413, 4414, 4415, 4400, 4420, 4411, 4369, 4418, 4421, 4384, 4399, 4388, 4416, 4409, 4431, 4428, 4417, 4436, 4423, 4422, 4434, 4424, 4440, 4426, 4433, 4441, 4425, 4432, 4439, 4446, 4452, 4450, 4429, 4444, 4457, 4445, 4454, 4427, 4448, 4455, 4459, 4449, 4456, 4463, 4437, 4447, 4435, 4460, 4467, 4430, 4464, 4451, 4474, 4477, 4458, 4479, 4469, 4480, 4475, 4466, 4473, 4468, 4481, 4471, 4438, 4461, 4453, 4465, 4483, 4487, 4476, 4485, 4488, 4472, 4478, 4490, 4484, 4486, 4492, 4493, 4489, 4443, 4495, 4496, 4497, 4491, 4498, 4508, 4500, 4502, 4505, 4506, 4511, 4516, 4512, 4514, 4515, 4499, 4513, 4482, 4503, 4501, 4522, 4520, 4504, 4518, 4525, 4510, 4527, 4523, 4532, 4528, 4536, 4521, 4524, 4537, 4509, 4526, 4517, 4534, 4530, 4531, 4539, 4546, 4541, 4535, 4544, 4549, 4529, 4533, 4507, 4545, 4538, 4555, 4547, 4548, 4550, 4559, 4552, 4554, 4561, 4553, 4557, 4567, 4540, 4558, 4568, 4566, 4573, 4569, 4560, 4563, 4571, 4564, 4565, 4574, 4576, 4579, 4572, 4580, 4570, 4582, 4584, 4577, 4586, 4562, 4578, 4581, 4585, 4589, 4592, 4593, 4590, 4595, 4600, 4604, 4594, 4583, 4597, 4591, 4602, 4606, 4608, 4603, 4605, 4596, 4607, 4613, 4617, 4618, 4615, 4621, 4622, 4611, 4625, 4623, 4587, 4628, 4601, 4620, 4610, 4619, 4609, 4616, 4624, 4588, 4627, 4614, 4629, 4612, 4635, 4638, 4632, 4634, 4637, 4641, 4640, 4644, 4645, 4648, 4647, 4642, 4649, 4631, 4633, 4650, 4653, 4651, 4652, 4639, 4654, 4656, 4646, 4657, 4660, 4662, 4658, 4664, 4663, 4666, 4665, 4668, 4669, 4667, 4655, 4671, 4674, 4672, 4676, 4673, 4675, 4643, 4679, 4677, 4683, 4680, 4685, 4687, 4688, 4686, 4681, 4689, 4690, 4691, 4692, 4694, 4693, 4684, 4696, 4697, 4699, 4700, 4695, 4702, 4706, 4708, 4709, 4704, 4707, 4712, 4711, 4710, 4713, 4698, 4715, 4703, 4719, 4720, 4721, 4722, 4726, 4717, 4725, 4723, 4727, 4728, 4724, 4729, 4730, 4714, 4732, 4735, 4736, 4737, 4738, 4903, 4743, 4800, 4791, 4798, 4804, 4787, 4784, 4790, 4788, 4754, 4842, 4786, 4783, 4781, 4747, 4779, 4777, 4774, 4772, 4753, 4780, 4771, 4778, 4797, 4770, 4782, 4773, 4765, 4766, 4761, 4763, 4767, 4769, 4785, 4764, 4748, 4760, 4776, 4759, 4762, 4756, 4768, 4758, 4740, 4749, 4744, 4752, 4751, 4745, 4946, 4741, 4750, 4739, 4742, 4746, 4718, 4943, 4734, 4755, 4939, 4935, 4940, 4944, 4949, 4936, 4941, 4948, 4918, 4931, 4925, 4915, 4914, 4927, 4922, 4900, 4910, 4902, 4912, 4889, 4908, 4895, 4886, 4921, 4909, 4897, 4893, 4885, 4873, 4896, 4876, 4913, 4890, 4881, 4891, 4866, 4858, 4871, 4869, 4892, 4872, 4867, 4862, 4868, 4863, 4905, 4859, 4855, 4852, 4848, 4850, 4853, 4845, 4846, 4847, 4870, 4838, 4841, 4824, 4833, 4834, 4825, 4835, 4844, 4819, 4827, 4823, 4840, 4836, 4821, 4829, 4820, 4813, 4857, 4815, 4814, 4816, 4811, 4807, 4818, 4802, 4808, 4809, 4822, 4801, 4810, 4812, 4805, 4799, 4803, 4792, 4789, 4953, 4956, 4955, 4957, 4958, 4959, 4960, 4961, 4962, 4964, 4966, 4967, 4968, 4971, 4972, 4969, 4974, 4973, 4976, 4975, 4977, 4982, 4979, 4980, 4983, 4981, 4986, 4984, 4985, 4987, 4988, 4989, 4993, 4996, 4994, 4995, 4999, 4997, 5001, 4998, 5000, 5002, 5003, 5004, 5007, 5006, 5008, 5010, 5009, 5015, 5011, 5013, 5023, 5016, 5019, 5012, 5020, 5021, 5028, 5022, 5026, 5025, 5027, 5030, 5032, 5029, 5031, 5033, 5024, 5036, 5037, 5039, 5038, 5040, 5042, 5041, 5043, 5046, 5044, 5045, 5047, 5051, 5050, 5053, 5055, 5058, 5057, 5059, 5061, 5069, 5064, 5063, 5068, 5066, 5070, 5071, 5067, 5065, 5074, 5072, 5073, 5075, 5077, 5076, 5078, 5079, 5080, 5083, 5085, 5087, 5082, 5086, 5088, 5089, 5090, 5091, 5093, 5096, 5092, 5094, 5097, 5102, 5099, 5104, 5100, 5101, 5105, 5107, 5106, 5108, 5111, 5112, 5109, 5110, 5113, 5114, 5116, 5122, 5119, 5121, 5125, 5120, 5124, 5126, 5132, 5127, 5142, 5130, 5128, 5129, 5139, 5131, 5135, 5137, 5134, 5141, 5138, 5145, 5143, 5144, 5150, 5149, 5147, 5155, 5152, 5159, 5151, 5157, 5154, 5162, 5163, 5158, 5156, 5160, 5161, 5164, 5165, 5166, 5169, 5133, 5171, 5174, 5170, 5172, 5173, 5175, 5177, 5179, 5180, 5184, 5188, 5181, 5182, 5186, 5185, 5190, 5192, 5191, 5193, 5195, 5197, 5196, 5200, 5198, 5199, 5201, 5213, 5203, 5204, 5206, 5212, 5207, 5211, 5209, 5210, 5215, 5216, 5214, 5217, 5219, 5220, 5221, 5222, 5223, 5224, 5228, 5227, 5225, 5233, 5229, 5232, 5231, 5234, 5208, 5235, 5236, 5238, 5237, 5240, 5239, 5242, 5243, 5245, 5246, 5249, 5248, 5250, 5253, 5252, 5257, 5254, 5258, 5260, 5261, 5259, 5264, 5265, 5266, 5268, 5267, 5270, 5271, 5272, 5275, 5276, 5277, 5278, 5283, 5290, 5285, 5287, 5288, 5289, 5293, 5286, 5292, 5291, 5295, 5296, 5297, 5284, 5303, 5301, 5304, 5305, 5306, 5309, 5310, 5311, 5313, 5312, 5315, 5314, 5318, 5316, 5319, 5321, 5317, 5325, 5323, 5320, 5326, 5322, 5324, 5328, 5327, 5329, 5330, 5331, 5332, 5333, 5335, 5334, 5336, 5337, 5343, 5340, 5338, 5339, 5342, 5344, 5341, 5347, 5345, 5346, 5349, 5348, 5351, 5352, 5353, 5355, 5356, 5361, 5362, 5359, 5363, 5365, 5368, 5364, 5366, 5371, 5370, 5369, 5372, 5374, 5375, 5377, 5376, 5379, 5378, 5383, 5384, 5381, 5380, 5382, 5388, 5389, 5387, 5391, 5390, 5393, 5394, 5395, 5398, 5396, 5397, 5399, 5400, 5401, 5403, 5409, 5404, 5406, 5410, 5408, 5411, 5412, 5413, 5415, 5414, 5419, 5420, 5421, 5425, 5422, 5423, 5424, 5427, 5426, 5428, 5430, 5429, 5433, 5434, 5436, 5435, 5437, 5439, 5438, 5440, 5441, 5442, 5443, 5447, 5446, 5448, 5451, 5453, 5463, 5452, 5450, 5455, 5454, 5461, 5456, 5465, 5459, 5462, 5466, 5464, 5467, 5469, 5468, 5472, 5471, 5477, 5474, 5475, 5482, 5476, 5479, 5478, 5481, 5504, 5484, 5488, 5485, 5487, 5486, 5492, 5493, 5491, 5490, 5489, 5494, 5495, 5496, 5502, 5499, 5497, 5498, 5500, 5503, 5501, 5521, 5506, 5508, 5514, 5511, 5510, 5513, 5519, 5517, 5518, 5523, 5515, 5522, 5520, 5525, 5526, 5530, 5527, 5529, 5532, 5535, 5537, 5538, 5540, 5536, 5541, 5546, 5543, 5544, 5545, 5549, 5548, 5551, 5547, 5555, 5550, 5553, 5552, 5557, 5556, 5554, 5558, 5561, 5562, 5565, 5567, 5563, 5564, 5566, 5568, 5569, 5570, 5571, 5572, 5575, 5576, 5589, 5574, 5577, 5579, 5578, 5580, 5582, 5584, 5583, 5588, 5590, 5591, 5592, 5593, 5598, 5595, 5594, 5597, 5600, 5605, 5602, 5599, 5607, 5613, 5611, 5610, 5616, 5614, 5612, 5615, 5618, 5622, 5626, 5619, 5623, 5625, 5621, 5628, 5629, 5627, 5630, 5632, 5631, 5634, 5635, 5639, 5637, 5636, 5638, 5640, 5641, 5642, 5643, 5644, 5645, 5646, 5648, 5651, 5650, 5649, 5652, 5655, 5654, 5658, 5657, 5663, 5659, 5661, 5662, 5664, 5666, 5665, 5668, 5667, 5670, 5672, 5675, 5674, 5677, 5676, 5679, 5682, 5683, 5678, 5681, 5687, 5685, 5689, 5688, 5690, 5692, 5693, 5697, 5694, 5696, 5700, 5698, 5702, 5701, 5703, 5704, 5708, 5707, 5706, 5710, 5711, 5712, 5713, 5714, 5717, 5716, 5718, 5720, 5722, 5723, 5724, 5725, 5726, 5728, 5733, 5731, 5734, 5730, 5732, 5735, 5736, 5737, 5738, 5742, 5741, 5750, 5744, 5746, 5748, 5751, 5754, 5749, 5753, 5752, 5758, 5756, 5755, 5757, 5759, 5760, 5762, 5765, 5767, 5768, 5766, 5769, 5772, 5770, 5771, 5773, 5774, 5776, 5779, 5783, 5778, 5781, 5782, 5784, 5787, 5789, 5788, 5791, 5790, 5796, 5798, 5793, 5792, 5795, 5797, 5799, 5801, 5800, 5804, 5802, 5803, 5808, 5806, 5812, 5810, 5811, 5814, 5815, 5813, 5816, 5818, 5817, 5819, 5821, 5820, 5823, 5824, 5822, 5825, 5826, 5827, 5828, 5786, 5830, 5831, 5833, 5834, 5835, 5836, 5838, 5837, 5839, 5842, 5840, 5841, 5844, 5847, 5852, 5849, 5848, 5845, 5846, 5850, 5854, 5862, 5855, 5869, 5858, 5856, 5864, 5861, 5859, 5860, 5863, 5866, 5867, 5870, 5871, 5873, 5876, 5878, 5875, 5877, 5879, 5881, 5880, 5884, 5886, 5882, 5883, 5885, 5889, 5892, 5894, 5893, 5902, 5897, 5896, 5899, 5900, 5904, 5906, 5908, 5909, 5912, 5911, 5910, 5916, 5914, 5917, 5915, 5921, 5920, 5925, 5924, 5926, 5922, 5928, 5923, 5927, 5929, 5931, 5932, 5937, 5933, 5934, 5936, 5938, 5939, 5940, 5942, 5935, 5944, 5945, 5946, 5948, 5949, 5950, 5951, 5954, 5955, 5960, 5957, 5959, 5962, 5963, 5961, 5964, 5968, 5967, 5966, 5971, 5969, 5972, 5970, 5973, 5974, 5976, 5975, 5977, 5979, 5978, 5983, 5981, 5985, 5984, 5986, 5987, 5988, 5991, 5992, 5990, 5993, 5995, 5996, 5998, 5997, 5999, 6000, 6001, 6003, 6004, 6005, 6006, 6012, 6007, 6009, 6011, 6019, 6010, 6013, 6016, 6017, 6018, 6021, 6022, 6020, 6023, 6046, 6045, 6036, 6038, 6037, 6044, 6057, 6035, 6031, 6030, 6041, 6032, 6028, 6026, 6029, 6048, 6033, 6039, 6025, 6085, 6087, 6086, 6084, 6070, 6080, 6082, 6077, 6075, 6078, 6076, 6081, 6063, 6074, 6069, 6072, 6071, 6066, 6034, 6065, 6067, 6040, 6056, 6062, 6064, 6049, 6058, 6061, 6059, 6053, 6055, 6050, 6052, 6060, 6047, 6054, 6042, 6051, 6043]\n"
     ]
    }
   ],
   "source": [
    "id = [int(i) for i in data_sed_chi_l5['id']]\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4360, 4360)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['SNR']>=5]), len(data_sed_chi_l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grism_id</th>\n",
       "      <th>wavelength</th>\n",
       "      <th>flux</th>\n",
       "      <th>z</th>\n",
       "      <th>SNR</th>\n",
       "      <th>continuum_sub_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aegis-26-G141_00469</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.094828</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aegis-26-G141_00703</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.40</td>\n",
       "      <td>20.695364</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aegis-26-G141_00836</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.56</td>\n",
       "      <td>6.308725</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aegis-26-G141_00910</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.05</td>\n",
       "      <td>4.627907</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aegis-26-G141_00937</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.51</td>\n",
       "      <td>8.418367</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>uds-23-G141_42763</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.185430</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>uds-05-G141_42909</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.974790</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18577</th>\n",
       "      <td>uds-25-G141_42927</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.11972591812810127, 0.11699151816036778, 0.1...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.177632</td>\n",
       "      <td>[0.11903046440555565, 0.11629269513745405, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18578</th>\n",
       "      <td>uds-25-G141_42956</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.10640179127421547, 0.10492161739585708, 0.1...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.127168</td>\n",
       "      <td>[0.10595676034947163, 0.10447454305889436, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18583</th>\n",
       "      <td>uds-05-G141_43311</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.408397</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8683 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  grism_id                                         wavelength  \\\n",
       "2      aegis-26-G141_00469  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "8      aegis-26-G141_00703  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "13     aegis-26-G141_00836  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "16     aegis-26-G141_00910  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "18     aegis-26-G141_00937  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "...                    ...                                                ...   \n",
       "18575    uds-23-G141_42763  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "18576    uds-05-G141_42909  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "18577    uds-25-G141_42927  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "18578    uds-25-G141_42956  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "18583    uds-05-G141_43311  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "\n",
       "                                                    flux     z        SNR  \\\n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.43   4.094828   \n",
       "8      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.40  20.695364   \n",
       "13     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.56   6.308725   \n",
       "16     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.05   4.627907   \n",
       "18     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.51   8.418367   \n",
       "...                                                  ...   ...        ...   \n",
       "18575  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...  1.34   4.185430   \n",
       "18576  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.45   2.974790   \n",
       "18577  [0.11972591812810127, 0.11699151816036778, 0.1...  0.99   3.177632   \n",
       "18578  [0.10640179127421547, 0.10492161739585708, 0.1...  0.92   3.127168   \n",
       "18583  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.67   7.408397   \n",
       "\n",
       "                                      continuum_sub_flux  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "16     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "18     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "18575  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002...  \n",
       "18576  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "18577  [0.11903046440555565, 0.11629269513745405, 0.1...  \n",
       "18578  [0.10595676034947163, 0.10447454305889436, 0.1...  \n",
       "18583  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[8683 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['SNR']>=2.5]\n",
    "data_subset = data[data['z']<1.7]\n",
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6078 1302 1303\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 70% train and 30% temp_test\n",
    "train_df, temp_test_df = train_test_split(data_subset, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temp_test into 50% test and 50% validation, which is 15% each of the original\n",
    "test_df, val_df = train_test_split(temp_test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(train_df),len(test_df),len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from SpecPT import (\n",
    "    SpecPT, \n",
    "    SpecPTForRedshift, \n",
    "    CustomLoadDataset_Autoencoder,\n",
    "    Swish,\n",
    "    # CustomLoadDataset_Redshift, \n",
    "    NMADLoss, \n",
    "    evaluate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSpecPTForRedshift(nn.Module):\n",
    "    def __init__(self, pretrained_model, additional_features_dim, output_features=1, num_mlp_blocks=5, mlp_dim=512, dropout_rate=0.2):\n",
    "        super(EnhancedSpecPTForRedshift, self).__init__()\n",
    "        \n",
    "        self.encoder = pretrained_model.transformer_encoder\n",
    "        self.proj_to_d_model = pretrained_model.proj_to_d_model\n",
    "        self.forward_conv = pretrained_model.forward_conv\n",
    "        \n",
    "        # Fine-tune the last few layers of the encoder\n",
    "        for param in list(self.encoder.parameters())[-4:]:\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Projection layer for additional features\n",
    "        self.additional_projection = nn.Sequential(\n",
    "            nn.Linear(additional_features_dim, 512),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.LayerNorm(512)\n",
    "        )\n",
    "        \n",
    "        # Early fusion layer before attention\n",
    "        self.pre_attention_fusion = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 512),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.LayerNorm(512)\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "        \n",
    "        self.mlp_blocks = nn.Sequential(\n",
    "            *[ImprovedResidualMLPBlock(mlp_dim, mlp_dim, dropout_rate) for _ in range(num_mlp_blocks)]\n",
    "        )\n",
    "        \n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(mlp_dim, mlp_dim // 2),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mlp_dim // 2, output_features),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, additional_data):\n",
    "        # Process spectral data\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.forward_conv(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.proj_to_d_model(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # Encode spectral features\n",
    "        encoded_features = self.encoder(x)\n",
    "        encoded_features = encoded_features.squeeze(0)\n",
    "        \n",
    "        # Process and combine additional data\n",
    "        additional_features = self.additional_projection(additional_data)\n",
    "        \n",
    "        # Combine features before attention\n",
    "        combined_features = torch.cat([encoded_features, additional_features], dim=-1)\n",
    "        fused_features = self.pre_attention_fusion(combined_features)\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        attn_output, _ = self.attention(fused_features, fused_features, fused_features)\n",
    "        x = attn_output + fused_features  # Residual connection\n",
    "        \n",
    "        # Process through MLP blocks\n",
    "        x = self.mlp_blocks(x)\n",
    "        \n",
    "        # Final prediction\n",
    "        redshift = self.prediction(x)\n",
    "        return redshift\n",
    "\n",
    "class ImprovedResidualMLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate):\n",
    "        super(ImprovedResidualMLPBlock, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, output_dim)\n",
    "        self.linear2 = nn.Linear(output_dim, output_dim)\n",
    "        self.swish = Swish()\n",
    "        self.layer_norm = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.swish(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = x + residual  # Residual connection\n",
    "        x = self.layer_norm(x)\n",
    "        return self.swish(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader for Redshift\n",
    "class CustomLoadDataset_Redshift(Dataset):\n",
    "    def __init__(self, df):\n",
    "        x = []\n",
    "        y = []\n",
    "        target_id = []\n",
    "            \n",
    "        for index, row in df.iterrows():\n",
    "            fl = row['flux']\n",
    "            if np.median(fl) > 0:\n",
    "                fl = fl / np.median(fl)\n",
    "                x.append(fl)\n",
    "                y.append(np.array([row['z']]))\n",
    "                target_id.append(row['grism_id'])\n",
    "\n",
    "        self.X = torch.from_numpy(np.stack(x, axis=0))\n",
    "        self.Y = torch.from_numpy(np.stack(y, axis=0))\n",
    "        self.t_id = target_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].float(), self.Y[idx].float(), idx, self.t_id[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(CustomLoadDataset_Redshift(val_df), batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(CustomLoadDataset_Redshift(test_df), batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "epochs = 800\n",
    "batch_size = 64\n",
    "lr = 1e-5 #orig = 0.001 or 1e-3, best with 5e-5\n",
    "\n",
    "config = {\n",
    "    \"input_size\": 7781,\n",
    "    \"d_model\": 512,\n",
    "    \"nhead\": 8,\n",
    "    \"num_encoder_layers\": 3,\n",
    "    \"num_decoder_layers\": 3,\n",
    "    \"dim_feedforward\": 2048,\n",
    "    \"learning_rate\": lr,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_mlp_blocks\": 5,\n",
    "    \"mlp_dim\": 512,\n",
    "    \"dropout_rate\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(CustomLoadDataset_Redshift(train_df), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
