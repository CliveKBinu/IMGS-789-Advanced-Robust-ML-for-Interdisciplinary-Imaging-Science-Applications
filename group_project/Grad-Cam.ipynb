{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758f92b4-645c-45d9-b48a-8b177abfc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neccesary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import random\n",
    "import glob, os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from scipy.ndimage.filters import gaussian_filter1d\n",
    "# import torchvision.models as models\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import matplotlib.pyplot as plt\n",
    "# from accelerate import Accelerator\n",
    "# cm = plt.get_cmap('RdYlBu')\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# from torch.nn import LayerNorm\n",
    "# import math\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import seaborn as sns\n",
    "# import matplotlib.colors as mcolors\n",
    "# import pandas as pd\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "# from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535c81be-f7bf-4473-bc6f-332285df94ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 2.63 s, total: 4.19 s\n",
      "Wall time: 18.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grism_id</th>\n",
       "      <th>wavelength</th>\n",
       "      <th>flux</th>\n",
       "      <th>z</th>\n",
       "      <th>SNR</th>\n",
       "      <th>continuum_sub_flux</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aegis-26-G141_00469</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>4.094828</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aegis-26-G141_00703</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.40</td>\n",
       "      <td>20.695364</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aegis-26-G141_00836</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.56</td>\n",
       "      <td>6.308725</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aegis-26-G141_00910</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.05</td>\n",
       "      <td>4.627907</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aegis-26-G141_00937</td>\n",
       "      <td>[10208.409432389317, 10209.33721533346, 10210....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1.51</td>\n",
       "      <td>8.418367</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               grism_id                                         wavelength  \\\n",
       "2   aegis-26-G141_00469  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "8   aegis-26-G141_00703  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "13  aegis-26-G141_00836  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "16  aegis-26-G141_00910  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "18  aegis-26-G141_00937  [10208.409432389317, 10209.33721533346, 10210....   \n",
       "\n",
       "                                                 flux     z        SNR  \\\n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.43   4.094828   \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.40  20.695364   \n",
       "13  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.56   6.308725   \n",
       "16  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.05   4.627907   \n",
       "18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  1.51   8.418367   \n",
       "\n",
       "                                   continuum_sub_flux  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "16  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Import all the data\n",
    "data = pd.read_pickle('grism_specPT.pkl')\n",
    "\n",
    "# pulling only datapoints with a SNR at or above 2.5 and a redshift below 1.7\n",
    "data = data[data['SNR']>=2.5]\n",
    "data_subset = data[data['z']<1.7]\n",
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "244e0a6f-51fc-4596-85cd-209e7b8a75db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 6078\n",
      "Validation set size: 1302\n",
      "Test set size: 1303\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 70% train and 30% temp_test\n",
    "train_df, temp_test_df = train_test_split(data_subset, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the temp_test into 50% test and 50% validation, which is 15% each of the original\n",
    "test_df, val_df = train_test_split(temp_test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the sizes of each set\n",
    "print(f'Train set size: {len(train_df)}')\n",
    "print(f'Validation set size: {len(test_df)}')\n",
    "print(f'Test set size: {len(val_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90c191-572d-4961-8f0a-996b2e6be417",
   "metadata": {},
   "source": [
    "## Loading in SpecPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c0646a-c32f-45f6-93be-b94ca2703c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpecPT import (\n",
    "    SpecPT, \n",
    "    SpecPTForRedshift, \n",
    "    CustomLoadDataset_Autoencoder,\n",
    "    Swish,\n",
    "    # CustomLoadDataset_Redshift, \n",
    "    NMADLoss, \n",
    "    evaluate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444470ef-3c2a-4cd6-9515-05b110eff050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSpecPTForRedshift(nn.Module):\n",
    "    def __init__(self, pretrained_model, output_features=1, num_mlp_blocks=5, mlp_dim=512, dropout_rate=0.2):\n",
    "        super(EnhancedSpecPTForRedshift, self).__init__()\n",
    "        \n",
    "        self.encoder = pretrained_model.transformer_encoder\n",
    "        self.proj_to_d_model = pretrained_model.proj_to_d_model\n",
    "        self.forward_conv = pretrained_model.forward_conv\n",
    "        \n",
    "        # Fine-tune the last few layers of the encoder\n",
    "        for param in list(self.encoder.parameters())[-4:]:\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.mlp_blocks = nn.Sequential(\n",
    "            *[ImprovedResidualMLPBlock(mlp_dim if i > 0 else 512, mlp_dim, dropout_rate) for i in range(num_mlp_blocks)]\n",
    "        )\n",
    "        \n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(mlp_dim, mlp_dim // 2),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mlp_dim // 2, output_features),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=512, num_heads=8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.forward_conv(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.proj_to_d_model(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        encoded_features = self.encoder(x)\n",
    "        encoded_features = encoded_features.squeeze(0)\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        attn_output, _ = self.attention(encoded_features, encoded_features, encoded_features)\n",
    "        x = attn_output + encoded_features  # Residual connection\n",
    "        \n",
    "        x = self.mlp_blocks(x)\n",
    "        redshift = self.prediction(x)\n",
    "        return redshift\n",
    "\n",
    "class ImprovedResidualMLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate):\n",
    "        super(ImprovedResidualMLPBlock, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, output_dim)\n",
    "        self.linear2 = nn.Linear(output_dim, output_dim)\n",
    "        self.swish = Swish()\n",
    "        self.layer_norm = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.swish(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = x + residual  # Residual connection\n",
    "        x = self.layer_norm(x)\n",
    "        return self.swish(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d55d4ef-7c0f-42cd-8729-d04ffce9d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader for Redshift\n",
    "class CustomLoadDataset_Redshift(Dataset):\n",
    "    def __init__(self, df):\n",
    "        x = []\n",
    "        y = []\n",
    "        target_id = []\n",
    "            \n",
    "        for index, row in df.iterrows():\n",
    "            fl = row['flux']\n",
    "            if np.median(fl) > 0:\n",
    "                fl = fl / np.median(fl)\n",
    "                x.append(fl)\n",
    "                y.append(np.array([row['z']]))\n",
    "                target_id.append(row['grism_id'])\n",
    "\n",
    "        self.X = torch.from_numpy(np.stack(x, axis=0))\n",
    "        self.Y = torch.from_numpy(np.stack(y, axis=0))\n",
    "        self.t_id = target_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].float(), self.Y[idx].float(), idx, self.t_id[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa666180-b079-483f-b05d-76275cb605d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(CustomLoadDataset_Redshift(val_df), batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(CustomLoadDataset_Redshift(test_df), batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca91b33-1c46-4659-bed8-d4cffad63ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm5957/miniconda3/envs/ml/lib/python3.9/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# defining our model\n",
    "model = SpecPT(input_size=7781) #, d_head=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83cd2365-7129-4638-8fc6-39312ef6fb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-2): 3 x TransformerDecoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer_decoder.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724384e-c99e-48ab-8192-973b8032887d",
   "metadata": {},
   "source": [
    "Following the tutorial from [Cam Metrics and Training Tutorial](https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/CAM%20Metrics%20And%20Tuning%20Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d30b7384-a79c-49f9-8255-91fd8771aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "# targeting the layers of the decoder\n",
    "target_layers = model.transformer_decoder.layers\n",
    "\n",
    "# applying the cam to the layers\n",
    "cam = GradCAM(model, target_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ecfccc-e5b3-4636-b3e6-e9ffd3924c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# choosing a galaxy example\n",
    "gal_ex = np.array([train_df.T[17364].wavelength,train_df.T[17364].flux])\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "tensor = transform(gal_ex).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd10657c-c85d-4456-8fff-0da8bde0a221",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m(img, mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GradCAM(model\u001b[38;5;241m=\u001b[39mmodel, target_layers\u001b[38;5;241m=\u001b[39mtarget_layers) \u001b[38;5;28;01mas\u001b[39;00m cam:\n\u001b[1;32m      4\u001b[0m     grayscale_cams \u001b[38;5;241m=\u001b[39m cam(input_tensor\u001b[38;5;241m=\u001b[39mtensor, targets\u001b[38;5;241m=\u001b[39mtargets)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_image' is not defined"
     ]
    }
   ],
   "source": [
    "# loading in the input tensor (issue: this seems to only take an image, \n",
    "# I am having troubles getting it to take in the 2D spectra)\n",
    "input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
    "    cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n",
    "cam = np.uint8(255*grayscale_cams[0, :])\n",
    "cam = cv2.merge([cam, cam, cam])\n",
    "images = np.hstack((np.uint8(255*img), cam , cam_image))\n",
    "Image.fromarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb03470f-7d82-4d38-acd3-a4651afa1e6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m targets \u001b[38;5;241m=\u001b[39m [FasterRCNNBoxScoreTarget(labels\u001b[38;5;241m=\u001b[39m\u001b[43mlabels\u001b[49m, bounding_boxes\u001b[38;5;241m=\u001b[39mboxes)]\n\u001b[1;32m      2\u001b[0m target_layers \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mbackbone]\n\u001b[1;32m      3\u001b[0m cam \u001b[38;5;241m=\u001b[39m AblationCAM(model,\n\u001b[1;32m      4\u001b[0m                   target_layers, \n\u001b[1;32m      5\u001b[0m                   use_cuda\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \n\u001b[1;32m      6\u001b[0m                   reshape_transform\u001b[38;5;241m=\u001b[39mfasterrcnn_reshape_transform,\n\u001b[1;32m      7\u001b[0m                   ablation_layer\u001b[38;5;241m=\u001b[39mAblationLayerFasterRCNN(),\n\u001b[1;32m      8\u001b[0m                   ratio_channels_to_ablate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "targets = [FasterRCNNBoxScoreTarget(labels=labels, bounding_boxes=boxes)]\n",
    "target_layers = [model.backbone]\n",
    "cam = AblationCAM(model,\n",
    "                  target_layers, \n",
    "                  use_cuda=torch.nn.cuda.is_available(), \n",
    "                  reshape_transform=fasterrcnn_reshape_transform,\n",
    "                  ablation_layer=AblationLayerFasterRCNN(),\n",
    "                  ratio_channels_to_ablate=1.0)\n",
    "\n",
    "# or a very fast alternative:\n",
    "\n",
    "cam = EigenCAM(model,\n",
    "              target_layers, \n",
    "              use_cuda=torch.nn.cuda.is_available(), \n",
    "              reshape_transform=fasterrcnn_reshape_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590fdbef-52c0-4f3a-85b7-0279ccde44a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
